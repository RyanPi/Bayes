{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Spam Filter with Naive Bayes Algorithm\n",
    "In this project, we'll be using the Naive Bayes Algorithm to build a spam filter for SMS messages. The spam filter will work in three main steps.\n",
    "\n",
    "1. The filter learns how humans classify a message as spam or non-spam\n",
    "2. The filter will use the classification criteria to estimate probabilities a new message is or is not spam\n",
    "3. The filter will then classify a message accordingly. If the probability is equal then the filter will ask for some human help for classification\n",
    "\n",
    "We are going to teach our filter by training it off of 5,572 SMS text messages that have been previously classified. This data set comes from Tiago A. Almeida and José María Gómez Hidalgo and can be accessed via the UCI Machine Learning Repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "sms = pd.read_csv(\"smsspamcollection/SMSSpamCollection\", sep=\"\\t\", header=None, names=['Label', 'SMS'])\n",
    "sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 5572 SMS messages 86.59% are real or 'ham' and 13.41% are spam.\n"
     ]
    }
   ],
   "source": [
    "vc = sms['Label'].value_counts()\n",
    "ham = round(vc[0]/sms.shape[0]*100,2)\n",
    "spam = round(vc[1]/sms.shape[0]*100,2)\n",
    "print(\"Out of 5572 SMS messages {}% are real or 'ham' and {}% are spam.\".format(ham, spam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing\n",
    "\n",
    "Before we develop our spam filter we need to devise a strategy for testing it's efficacy. We also need to make sure we give the spam filter enough data to be ready for the test. As a result, we will split our data into two categories: training and testing. The training set will be used to train the spam filter to classify spam and ham. The test set will determine our spam filter's efficacy. \n",
    "\n",
    "The categorization of the data will be split 80%/20%, training and testing respectively. There will be 4,458 training messages and 1,114 testing messages. The spam filter's goal is to classify new messages with an 80% or greater accuracy rate. We will be able to verify the accuracy rate because the 20%, the testing data, has already been classified as spam or ham.\n",
    "\n",
    "To get this going, we need to randomize the dataset in order to make sure spam and ham messages are distributed randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yep, by the pretty sculpture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4028</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes, princess. Are you going to make me moan?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>958</th>\n",
       "      <td>ham</td>\n",
       "      <td>Welp apparently he retired</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4642</th>\n",
       "      <td>ham</td>\n",
       "      <td>Havent.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4674</th>\n",
       "      <td>ham</td>\n",
       "      <td>I forgot 2 ask ü all smth.. There's a card on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>ham</td>\n",
       "      <td>We're all getting worried over here, derek and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5192</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh oh... Den muz change plan liao... Go back h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>ham</td>\n",
       "      <td>CERI U REBEL! SWEET DREAMZ ME LITTLE BUDDY!! C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>spam</td>\n",
       "      <td>Text &amp; meet someone sexy today. U can find a d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5157</th>\n",
       "      <td>ham</td>\n",
       "      <td>K k:) sms chat with me.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "1078   ham                       Yep, by the pretty sculpture\n",
       "4028   ham      Yes, princess. Are you going to make me moan?\n",
       "958    ham                         Welp apparently he retired\n",
       "4642   ham                                            Havent.\n",
       "4674   ham  I forgot 2 ask ü all smth.. There's a card on ...\n",
       "...    ...                                                ...\n",
       "905    ham  We're all getting worried over here, derek and...\n",
       "5192   ham  Oh oh... Den muz change plan liao... Go back h...\n",
       "3980   ham  CERI U REBEL! SWEET DREAMZ ME LITTLE BUDDY!! C...\n",
       "235   spam  Text & meet someone sexy today. U can find a d...\n",
       "5157   ham                            K k:) sms chat with me.\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = sms.sample(frac=1, random_state=1)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4458, 2)\n",
      "(1114, 2)\n",
      "5572\n",
      "4457\n"
     ]
    }
   ],
   "source": [
    "eighty_percent = int((5572*.8))\n",
    "training_set = sample[:eighty_percent+1].copy()\n",
    "testing_set = sample[eighty_percent:-1].copy()\n",
    "print(training_set.shape)\n",
    "print(testing_set.shape)\n",
    "print(training_set.shape[0] + testing_set.shape[0])\n",
    "print(eighty_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set.reset_index(inplace=True, drop=True)\n",
    "testing_set.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Training Set: out of 4458 rows there are 3858 counts of ham representing 86.54% and 600 counts of spam representing 13.46%.\n"
     ]
    }
   ],
   "source": [
    "training_v_counts = training_set['Label'].value_counts()\n",
    "training_ham_count = training_v_counts[0]\n",
    "training_spam_count = training_v_counts[1]\n",
    "training_ham_percent = round(training_ham_count/training_set.shape[0]*100,2)\n",
    "training_spam_percent = round(training_spam_count/training_set.shape[0]*100,2)\n",
    "print(\"For the Training Set: out of {} rows there are {} counts of ham representing {}% and {} counts of spam representing {}%.\"\n",
    "      .format(training_set.shape[0],training_ham_count, training_ham_percent, training_spam_count, training_spam_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the Testing Set: out of 1114 rows there are 967 counts of ham representing 86.8% and 147 counts of spam representing 13.2%.\n"
     ]
    }
   ],
   "source": [
    "testing_v_counts = testing_set['Label'].value_counts()\n",
    "testing_ham_count = testing_v_counts[0]\n",
    "testing_spam_count = testing_v_counts[1]\n",
    "testing_ham_percent = round(testing_ham_count/testing_set.shape[0]*100,2)\n",
    "testing_spam_percent = round(testing_spam_count/testing_set.shape[0]*100,2)\n",
    "print(\"For the Testing Set: out of {} rows there are {} counts of ham representing {}% and {} counts of spam representing {}%.\"\n",
    "      .format(testing_set.shape[0],testing_ham_count, testing_ham_percent, testing_spam_count, testing_spam_percent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code the `SMS` dataset was randomized and then split into two distince datasets for training data and testing data. The data sets were tested to ensure they were split correctly with 80% of the original `SMS` data set going to the training set and the remaining 20% of orginal values allocated to the testing set. Additional inspection was performed to measure the percentages of ham and spam messages in the trainin sets. The original `SMS` data set had a ratio of 86%/14% ham to spam. The `training_set` and `testing_set` dataframes have similar ratio of 87%/13% ham to spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Our Data\n",
    "With our training and test data sorted we need to take a look at how to extract the probabilities that a given message is spam or ham. In order to achieve this we'll need to begin cleaning the messages so only relevant words remain. In doing so we'll need to remove punctuation and remove capitalized words and letters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>go until jurong point  crazy   available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok lar    joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>u dun say so early hor    u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>nah i don t think he goes to usf  he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>will ü b going to esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>pity    was in mood for that  so   any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>the guy did some bitching but i acted like i d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>rofl  its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS\n",
       "0      ham  go until jurong point  crazy   available only ...\n",
       "1      ham                      ok lar    joking wif u oni   \n",
       "2     spam  free entry in 2 a wkly comp to win fa cup fina...\n",
       "3      ham  u dun say so early hor    u c already then say   \n",
       "4      ham  nah i don t think he goes to usf  he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  this is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               will ü b going to esplanade fr home \n",
       "5569   ham  pity    was in mood for that  so   any other s...\n",
       "5570   ham  the guy did some bitching but i acted like i d...\n",
       "5571   ham                         rofl  its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def cleaner(series):\n",
    "    return re.sub(\"\\W\", \" \", series).lower()\n",
    "\n",
    "sms['SMS'] = sms['SMS'].apply(cleaner)\n",
    "sms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Vocabulary and Training Set\n",
    "Now that the SMS messages have been cleaned up to only contain word values and made lower-case, we can beging to compile the vocabulary for the dataset. As a refresher a vocabulary is a list of all the unique words in the dataset. Once we have created our vocabulary we'll be able to analyze each message against it to understand how often a particular word appears in a message. By comparing the frequency of particular words in a message against the frquency of words in other messages, we'll be able to predict if a given message is ham or spam. This is the fundamental logic of how we'll train the algorithm.\n",
    "\n",
    "Let's get started by building our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set['SMS'] = training_set['SMS'].apply(cleaner)\n",
    "testing_set['SMS'] = testing_set['SMS'].apply(cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7783"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = []\n",
    "\n",
    "training_set['word_list'] = training_set['SMS'].str.split()\n",
    "for sms in training_set['word_list']:\n",
    "    for word in sms:\n",
    "        if word not in vocab:\n",
    "            vocab.append(word)\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with our vocabulary set we can build our dictionary to test for word frquencies in spam and ham messages. This is gunna be tricky. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>word_list</th>\n",
       "      <th>yep</th>\n",
       "      <th>by</th>\n",
       "      <th>the</th>\n",
       "      <th>pretty</th>\n",
       "      <th>sculpture</th>\n",
       "      <th>yes</th>\n",
       "      <th>princess</th>\n",
       "      <th>...</th>\n",
       "      <th>beauty</th>\n",
       "      <th>hides</th>\n",
       "      <th>secrets</th>\n",
       "      <th>n8</th>\n",
       "      <th>jewelry</th>\n",
       "      <th>related</th>\n",
       "      <th>trade</th>\n",
       "      <th>arul</th>\n",
       "      <th>bx526</th>\n",
       "      <th>wherre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  \\\n",
       "0   ham                       yep  by the pretty sculpture   \n",
       "1   ham      yes  princess  are you going to make me moan    \n",
       "2   ham                         welp apparently he retired   \n",
       "3   ham                                            havent    \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ...   \n",
       "\n",
       "                                           word_list  yep  by  the  pretty  \\\n",
       "0                  [yep, by, the, pretty, sculpture]    1   1    1       1   \n",
       "1  [yes, princess, are, you, going, to, make, me,...    0   0    0       0   \n",
       "2                    [welp, apparently, he, retired]    0   0    0       0   \n",
       "3                                           [havent]    0   0    0       0   \n",
       "4  [i, forgot, 2, ask, ü, all, smth, there, s, a,...    0   0    0       0   \n",
       "\n",
       "   sculpture  yes  princess  ...  beauty  hides  secrets  n8  jewelry  \\\n",
       "0          1    0         0  ...       0      0        0   0        0   \n",
       "1          0    1         1  ...       0      0        0   0        0   \n",
       "2          0    0         0  ...       0      0        0   0        0   \n",
       "3          0    0         0  ...       0      0        0   0        0   \n",
       "4          0    0         0  ...       0      0        0   0        0   \n",
       "\n",
       "   related  trade  arul  bx526  wherre  \n",
       "0        0      0     0      0       0  \n",
       "1        0      0     0      0       0  \n",
       "2        0      0     0      0       0  \n",
       "3        0      0     0      0       0  \n",
       "4        0      0     0      0       0  \n",
       "\n",
       "[5 rows x 7786 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_freq_sms = {unique_word: [0]*len(training_set['word_list']) for unique_word in vocab}\n",
    "'''\n",
    "The code above creates a dictionary where each key is a unique word from the vocabulary. The key or word,\n",
    "has a value of '0' for every row in the dataset essentially a 0 for each message. We'll loop through the\n",
    "dataset rows evaluating the words in each sms and then updating the particular word's count in the dictionary \n",
    "at the index it appears in the dataset row.\n",
    "'''\n",
    "\n",
    "for index,sms in enumerate(training_set['word_list']):\n",
    "    for word in sms:\n",
    "        words_freq_sms[word][index]+=1\n",
    "\n",
    "df_words_per_sms = pd.DataFrame(words_freq_sms)\n",
    "final_training_set = pd.concat([training_set, df_words_per_sms], axis=1)\n",
    "final_training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Probability Constants\n",
    "In the above code we developed two crucial components for our spam filter: the vocabulary and the word count per sms message data. In order to calculate the probabilities that a message is spam or ham, we must know the vocabulary and we must know the frequency of each word in each message. \n",
    "\n",
    "To calculate our probabilities of P(Spam) and P(Ham) we will also need to find NSpam, NHam, and NVocabulary. NSpam is equal to the number of words in all the spam messages. NHam is equal to the number of words in all non-spam messages. NVocabulary is equal to all unique words in both Spam and Ham messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13458950201884254 0.8654104979811574\n"
     ]
    }
   ],
   "source": [
    "count_spam = len(final_training_set[final_training_set['Label']==\"spam\"])\n",
    "p_spam = count_spam/len(final_training_set)\n",
    "p_ham = 1-p_spam\n",
    "print(p_spam, p_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>word_list</th>\n",
       "      <th>yep</th>\n",
       "      <th>by</th>\n",
       "      <th>the</th>\n",
       "      <th>pretty</th>\n",
       "      <th>sculpture</th>\n",
       "      <th>yes</th>\n",
       "      <th>princess</th>\n",
       "      <th>...</th>\n",
       "      <th>hides</th>\n",
       "      <th>secrets</th>\n",
       "      <th>n8</th>\n",
       "      <th>jewelry</th>\n",
       "      <th>related</th>\n",
       "      <th>trade</th>\n",
       "      <th>arul</th>\n",
       "      <th>bx526</th>\n",
       "      <th>wherre</th>\n",
       "      <th>total_words_per_sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7787 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  \\\n",
       "0   ham                       yep  by the pretty sculpture   \n",
       "1   ham      yes  princess  are you going to make me moan    \n",
       "2   ham                         welp apparently he retired   \n",
       "3   ham                                            havent    \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ...   \n",
       "\n",
       "                                           word_list  yep  by  the  pretty  \\\n",
       "0                  [yep, by, the, pretty, sculpture]    1   1    1       1   \n",
       "1  [yes, princess, are, you, going, to, make, me,...    0   0    0       0   \n",
       "2                    [welp, apparently, he, retired]    0   0    0       0   \n",
       "3                                           [havent]    0   0    0       0   \n",
       "4  [i, forgot, 2, ask, ü, all, smth, there, s, a,...    0   0    0       0   \n",
       "\n",
       "   sculpture  yes  princess  ...  hides  secrets  n8  jewelry  related  trade  \\\n",
       "0          1    0         0  ...      0        0   0        0        0      0   \n",
       "1          0    1         1  ...      0        0   0        0        0      0   \n",
       "2          0    0         0  ...      0        0   0        0        0      0   \n",
       "3          0    0         0  ...      0        0   0        0        0      0   \n",
       "4          0    0         0  ...      0        0   0        0        0      0   \n",
       "\n",
       "   arul  bx526  wherre  total_words_per_sms  \n",
       "0     0      0       0                    5  \n",
       "1     0      0       0                    9  \n",
       "2     0      0       0                    4  \n",
       "3     0      0       0                    1  \n",
       "4     0      0       0                   26  \n",
       "\n",
       "[5 rows x 7787 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_training_set['total_words_per_sms'] = final_training_set.iloc[:,3:].apply(sum, axis=1)\n",
    "final_training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72427 72427\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>word_list</th>\n",
       "      <th>yep</th>\n",
       "      <th>by</th>\n",
       "      <th>the</th>\n",
       "      <th>pretty</th>\n",
       "      <th>sculpture</th>\n",
       "      <th>yes</th>\n",
       "      <th>princess</th>\n",
       "      <th>...</th>\n",
       "      <th>hides</th>\n",
       "      <th>secrets</th>\n",
       "      <th>n8</th>\n",
       "      <th>jewelry</th>\n",
       "      <th>related</th>\n",
       "      <th>trade</th>\n",
       "      <th>arul</th>\n",
       "      <th>bx526</th>\n",
       "      <th>wherre</th>\n",
       "      <th>total_words_per_sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>havent</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i forgot 2 ask ü all smth   there s a card on ...</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7787 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  \\\n",
       "0   ham                       yep  by the pretty sculpture   \n",
       "1   ham      yes  princess  are you going to make me moan    \n",
       "2   ham                         welp apparently he retired   \n",
       "3   ham                                            havent    \n",
       "4   ham  i forgot 2 ask ü all smth   there s a card on ...   \n",
       "\n",
       "                                           word_list  yep  by  the  pretty  \\\n",
       "0                  [yep, by, the, pretty, sculpture]    1   1    1       1   \n",
       "1  [yes, princess, are, you, going, to, make, me,...    0   0    0       0   \n",
       "2                    [welp, apparently, he, retired]    0   0    0       0   \n",
       "3                                           [havent]    0   0    0       0   \n",
       "4  [i, forgot, 2, ask, ü, all, smth, there, s, a,...    0   0    0       0   \n",
       "\n",
       "   sculpture  yes  princess  ...  hides  secrets  n8  jewelry  related  trade  \\\n",
       "0          1    0         0  ...      0        0   0        0        0      0   \n",
       "1          0    1         1  ...      0        0   0        0        0      0   \n",
       "2          0    0         0  ...      0        0   0        0        0      0   \n",
       "3          0    0         0  ...      0        0   0        0        0      0   \n",
       "4          0    0         0  ...      0        0   0        0        0      0   \n",
       "\n",
       "   arul  bx526  wherre  total_words_per_sms  \n",
       "0     0      0       0                    5  \n",
       "1     0      0       0                    9  \n",
       "2     0      0       0                    4  \n",
       "3     0      0       0                    1  \n",
       "4     0      0       0                   26  \n",
       "\n",
       "[5 rows x 7787 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nspam = final_training_set[final_training_set['Label']==\"spam\"]['total_words_per_sms'].sum()\n",
    "nham = final_training_set[final_training_set['Label']==\"ham\"]['total_words_per_sms'].sum()\n",
    "nvocab = len(vocab)\n",
    "i = final_training_set['total_words_per_sms'].sum()\n",
    "v = nspam + nham\n",
    "aplha = 1\n",
    "print(v,i)\n",
    "final_training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the above values are going to be constants in our program it is wise that we categorize them as such. The code below will reassign the values to the constant convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPAM = nspam\n",
    "N_HAM = nham\n",
    "N_VOCAB = nvocab\n",
    "P_SPAM = p_spam\n",
    "P_HAM = p_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Parameters\n",
    "Although we have calculated our constants of the training set data, we know that P(word|Spam) and P(word|Ham) will vary depending on the word. Using the training set data we can calculate these Ps or Parameters and treat them as constants as well--provided we make no changes to the training dataset. The vocabulary contains 7783 unique words so getting the parameters calculated means we will have 15,566 probabilities to calculate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_w_given_spam(wc_given_spam):\n",
    "    return (wc_given_spam+1)/(N_SPAM+1*N_VOCAB)\n",
    "\n",
    "def p_w_given_ham(wc_given_ham):\n",
    "    return(wc_given_ham+1)/(N_HAM+1*N_VOCAB)\n",
    "\n",
    "p_word_spam ={unique_word: 0 for unique_word in vocab}\n",
    "\n",
    "spam_set = final_training_set[final_training_set['Label']==\"spam\"]\n",
    "\n",
    "for word in vocab:\n",
    "    wc = spam_set[word].sum()\n",
    "    p_word_spam[word] = p_w_given_spam(wc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_word_ham = {unique_word: 0 for unique_word in vocab}\n",
    "\n",
    "ham_set = final_training_set[final_training_set['Label']==\"ham\"]\n",
    "\n",
    "for word in vocab:\n",
    "    wc = ham_set[word].sum()\n",
    "    p_word_ham[word] = p_w_given_ham(wc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying a New Message\n",
    "Now that we have our constants and the parameters of our training data, we can work on building the function that allows the filter to classify a given message as spam or ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "    #do some cleaning of the message, update to lower case and remove punctuation\n",
    "    message = message.replace(\"\\W\",\" \")\n",
    "    message = message.lower()\n",
    "    s_message = message.split()\n",
    "    \n",
    "    #calculate P(Spam|Message)\n",
    "    p_given_word = 1\n",
    "    for word in s_message:\n",
    "        if word in p_word_spam:            \n",
    "            p_given_word *= p_word_spam[word]\n",
    "    p_spam_given_message = P_SPAM * p_given_word\n",
    "    \n",
    "    #calculate P(Ham|Message)\n",
    "    p_g_w = 1\n",
    "    for word in s_message:\n",
    "        if word in p_word_ham:\n",
    "            p_g_w *= p_word_ham[word]\n",
    "    p_ham_given_message = P_HAM * p_g_w\n",
    "    \n",
    "    #Compare P(Spam|Message) to P(Ham|Message) and return a classification label\n",
    "    if p_spam_given_message > p_ham_given_message:\n",
    "        return \"spam\"\n",
    "    elif p_spam_given_message < p_ham_given_message:\n",
    "        return \"ham\"\n",
    "    else:\n",
    "        return \"Undetermined. Need some human help, beep bop.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_1 = \"WINNER!! This is the secret code to unlock the money: C3421.\"\n",
    "message_2 = \"Sounds good, Tom, then see u there\"\n",
    "\n",
    "classify(message_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ham'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(message_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Algorithm and Measuring the Accuracy\n",
    "Above we built out a function that will take a given message, determine the probability of spam or ham and then label the message. Below we're going to run the algorithm on our `testing_set`. We'll then compare the human provided label to our machine learning algorithm and see if we reach our goal of over 80% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>machine_classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>wherre s my boytoy</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>later i guess  i needa do mcat study too</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>but i haf enuff space got like 4 mb</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>had your mobile 10 mths  update to latest oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>all sounds good  fingers   makes it difficult ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  \\\n",
       "0   ham                           wherre s my boytoy         \n",
       "1   ham          later i guess  i needa do mcat study too    \n",
       "2   ham             but i haf enuff space got like 4 mb      \n",
       "3  spam  had your mobile 10 mths  update to latest oran...   \n",
       "4   ham  all sounds good  fingers   makes it difficult ...   \n",
       "\n",
       "  machine_classification  \n",
       "0                    ham  \n",
       "1                    ham  \n",
       "2                    ham  \n",
       "3                   spam  \n",
       "4                    ham  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_set['machine_classification'] = testing_set['SMS'].apply(classify)\n",
    "testing_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9874326750448833"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_messages = len(testing_set)\n",
    "correct = 0\n",
    "for i,d  in testing_set.iterrows():\n",
    "    if d['Label'] == d['machine_classification']:\n",
    "        correct+=1\n",
    "\n",
    "accuracy = correct/total_messages\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "The Bayes algorithm produced from the training data resulted in a 98.7% accuracy rate in predicting whether an SMS message was Spam. This is a great start for our algorithm but it does require additional testing. This datset has the luxury of already being classified as Spam or Ham. To really validate our model, we need to test it on additional data. Further testing could include running the algorithm against an entire list of Spam messages or known Ham messages. With this, we can analyse the frequency of predicting false positives, messages that are Ham but classified as Spam and false negatives, messages that are Spam but classified as Ham."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
